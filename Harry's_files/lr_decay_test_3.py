import matplotlib.pyplot as plt
from scipy.stats import gaussian_kde, chisquare
from scipy.optimize import curve_fit
from operator import itemgetter
import numpy as np
import json
#data_lr = [9.990009e-05, 9.9800396e-05, 9.970089e-05, 9.9601595e-05, 9.950248e-05, 9.940357e-05, 9.930487e-05, 9.920634e-05, 9.910803e-05, 9.90099e-05, 9.8911965e-05, 9.881423e-05, 9.871668e-05, 9.861932e-05, 9.852216e-05, 9.842519e-05, 9.832842e-05, 9.823182e-05, 9.813542e-05, 9.8039214e-05, 9.7943186e-05, 9.784736e-05, 9.7751705e-05, 9.7656244e-05, 9.756097e-05, 9.746588e-05, 9.737098e-05, 9.7276265e-05, 9.718172e-05, 9.708738e-05, 9.699321e-05, 9.6899224e-05, 9.680542e-05, 9.6711796e-05, 9.661836e-05, 9.6525095e-05, 9.643202e-05, 9.6339114e-05, 9.624638e-05, 9.6153846e-05, 9.606148e-05, 9.5969284e-05, 9.587728e-05, 9.5785435e-05, 9.569378e-05, 9.560229e-05, 9.551098e-05, 9.541985e-05, 9.532888e-05, 9.5238094e-05, 9.514748e-05, 9.5057025e-05, 9.496676e-05, 9.4876654e-05, 9.478673e-05, 9.469697e-05, 9.460737e-05, 9.4517956e-05, 9.44287e-05, 9.433962e-05, 9.42507e-05, 9.416195e-05, 9.407338e-05, 9.3984956e-05, 9.3896706e-05, 9.380863e-05, 9.372071e-05, 9.363296e-05, 9.3545365e-05, 9.345794e-05, 9.337068e-05, 9.3283576e-05, 9.319665e-05, 9.310987e-05, 9.302325e-05, 9.29368e-05, 9.28505e-05, 9.276438e-05, 9.2678405e-05, 9.2592585e-05, 9.250694e-05, 9.242144e-05, 9.233611e-05, 9.225092e-05, 9.2165894e-05, 9.2081034e-05, 9.199632e-05, 9.191176e-05, 9.1827365e-05, 9.174312e-05, 9.165903e-05, 9.1575086e-05, 9.14913e-05, 9.140768e-05, 9.13242e-05, 9.124088e-05, 9.11577e-05, 9.1074675e-05, 9.099181e-05, 9.090909e-05, 9.082652e-05, 9.07441e-05, 9.066182e-05, 9.057971e-05, 9.0497735e-05, 9.041592e-05, 9.033424e-05, 9.02527e-05, 9.017133e-05, 9.0090085e-05, 9.0008994e-05, 8.992806e-05, 8.984726e-05, 8.976661e-05, 8.9686095e-05, 8.9605724e-05, 8.9525514e-05, 8.9445435e-05, 8.936551e-05, 8.928571e-05, 8.9206056e-05, 8.912656e-05, 8.904719e-05, 8.896797e-05, 8.888889e-05, 8.880994e-05, 8.873115e-05, 8.865248e-05, 8.8573965e-05, 8.849557e-05, 8.841733e-05, 8.833922e-05, 8.826125e-05, 8.818341e-05, 8.810573e-05, 8.8028166e-05, 8.795075e-05, 8.787346e-05, 8.77963e-05, 8.7719294e-05, 8.764242e-05, 8.756568e-05, 8.748906e-05, 8.741258e-05, 8.7336244e-05, 8.726003e-05, 8.718396e-05, 8.710801e-05, 8.70322e-05, 8.695652e-05, 8.6880966e-05, 8.680556e-05, 8.6730266e-05, 8.6655105e-05, 8.658008e-05, 8.6505184e-05, 8.643042e-05, 8.635579e-05, 8.6281274e-05, 8.62069e-05, 8.613264e-05, 8.605852e-05, 8.5984524e-05, 8.591065e-05, 8.583691e-05, 8.576329e-05, 8.56898e-05, 8.561644e-05, 8.554319e-05, 8.5470085e-05, 8.539709e-05, 8.532422e-05, 8.525149e-05, 8.517887e-05, 8.510638e-05, 8.5034015e-05, 8.4961765e-05, 8.4889645e-05, 8.4817635e-05, 8.4745756e-05, 8.4674e-05, 8.460236e-05, 8.453085e-05, 8.4459454e-05, 8.4388186e-05, 8.431703e-05, 8.424599e-05, 8.417509e-05, 8.4104286e-05, 8.403361e-05, 8.396305e-05, 8.389261e-05, 8.38223e-05, 8.375209e-05, 8.3682e-05, 8.361204e-05, 8.354218e-05, 8.3472456e-05, 8.340283e-05, 8.3333325e-05, 8.326395e-05, 8.3194675e-05, 8.312551e-05, 8.3056475e-05, 8.298755e-05, 8.291874e-05, 8.285004e-05, 8.278146e-05, 8.2712984e-05, 8.264463e-05, 8.2576385e-05, 8.2508246e-05, 8.244022e-05, 8.2372324e-05, 8.230452e-05, 8.2236846e-05, 8.216927e-05, 8.2101804e-05, 8.203445e-05, 8.1967206e-05, 8.1900085e-05, 8.183306e-05, 8.176614e-05, 8.169935e-05, 8.163265e-05, 8.156606e-05, 8.149959e-05, 8.1433216e-05, 8.136696e-05, 8.130081e-05, 8.123477e-05, 8.116883e-05, 8.1103e-05, 8.103728e-05, 8.097166e-05, 8.0906146e-05, 8.084074e-05, 8.077544e-05, 8.071025e-05, 8.064516e-05, 8.058017e-05, 8.0515296e-05, 8.045052e-05, 8.038585e-05, 8.032128e-05, 8.025682e-05, 8.019246e-05, 8.01282e-05, 8.006404e-05, 8e-05, 7.993605e-05, 7.98722e-05, 7.980846e-05, 7.9744816e-05, 7.9681275e-05, 7.961783e-05, 7.95545e-05, 7.9491256e-05, 7.9428115e-05, 7.9365076e-05, 7.930214e-05, 7.92393e-05, 7.917656e-05, 7.9113925e-05, 7.905138e-05, 7.898894e-05, 7.89266e-05, 7.886435e-05, 7.88022e-05, 7.874016e-05, 7.8678204e-05, 7.8616344e-05, 7.855459e-05, 7.849293e-05, 7.8431374e-05, 7.83699e-05, 7.8308534e-05, 7.8247256e-05, 7.818608e-05, 7.8125e-05, 7.806401e-05, 7.800311e-05, 7.794232e-05, 7.788162e-05, 7.7821e-05, 7.7760495e-05, 7.770008e-05, 7.763975e-05, 7.757951e-05, 7.751938e-05, 7.745933e-05, 7.7399374e-05, 7.733952e-05, 7.727975e-05, 7.722007e-05, 7.716049e-05, 7.7100995e-05, 7.70416e-05, 7.698229e-05, 7.6923076e-05]
#data_lr = [9.90099e-05, 9.8039214e-05, 9.708738e-05, 9.6153846e-05, 9.5238094e-05, 9.433962e-05, 9.345794e-05, 9.2592585e-05, 9.174312e-05, 9.090909e-05, 9.0090085e-05, 8.928571e-05, 8.849557e-05, 8.7719294e-05, 8.695652e-05, 8.62069e-05, 8.5470085e-05, 8.474576e-05, 8.403361e-05, 8.3333325e-05, 8.264463e-05, 8.1967206e-05, 8.130081e-05, 8.064516e-05, 8e-05, 7.9365076e-05, 7.874016e-05, 7.8125e-05, 7.751938e-05, 7.6923076e-05, 7.633588e-05, 7.5757576e-05, 7.518797e-05, 7.462686e-05, 7.407407e-05, 7.352941e-05, 7.29927e-05, 7.2463765e-05, 7.194244e-05, 7.142857e-05, 7.092198e-05, 7.042254e-05, 6.993007e-05, 6.944444e-05, 6.896551e-05, 6.8493144e-05, 6.8027206e-05, 6.756756e-05, 6.7114095e-05, 6.666667e-05, 6.622516e-05, 6.578947e-05, 6.5359476e-05, 6.493506e-05, 6.451613e-05, 6.410256e-05, 6.369427e-05, 6.329114e-05, 6.289309e-05, 6.25e-05, 6.21118e-05, 6.1728395e-05, 6.134969e-05, 6.097561e-05, 6.060606e-05, 6.0240964e-05, 5.988024e-05, 5.9523805e-05, 5.9171594e-05, 5.8823527e-05, 5.847953e-05, 5.8139532e-05, 5.7803467e-05, 5.747126e-05, 5.7142857e-05, 5.6818182e-05, 5.6497174e-05, 5.6179775e-05, 5.5865923e-05, 5.5555556e-05, 5.524862e-05, 5.4945056e-05, 5.464481e-05, 5.4347827e-05, 5.4054057e-05, 5.3763444e-05, 5.3475935e-05, 5.319149e-05, 5.291005e-05, 5.2631578e-05, 5.235602e-05, 5.2083335e-05, 5.181347e-05, 5.1546387e-05, 5.1282048e-05, 5.1020404e-05, 5.076142e-05, 5.050505e-05, 5.0251256e-05, 5e-05, 4.975124e-05, 4.950495e-05, 4.926108e-05, 4.9019607e-05, 4.8780486e-05, 4.854369e-05, 4.830918e-05, 4.8076923e-05, 4.7846886e-05, 4.7619047e-05, 4.739336e-05, 4.716981e-05, 4.6948353e-05, 4.6728972e-05, 4.6511625e-05, 4.62963e-05, 4.6082947e-05, 4.5871562e-05, 4.56621e-05, 4.5454548e-05, 4.5248868e-05, 4.5045042e-05, 4.4843047e-05, 4.4642857e-05, 4.4444445e-05, 4.4247787e-05, 4.4052864e-05, 4.3859647e-05, 4.3668122e-05, 4.347826e-05, 4.329004e-05, 4.310345e-05, 4.2918455e-05, 4.2735042e-05, 4.255319e-05, 4.2372878e-05, 4.2194093e-05, 4.2016803e-05, 4.1841005e-05, 4.1666663e-05, 4.149378e-05, 4.1322313e-05, 4.1152267e-05, 4.0983603e-05, 4.081633e-05, 4.0650404e-05, 4.0485833e-05, 4.032258e-05, 4.016064e-05, 4e-05, 3.9840637e-05, 3.9682538e-05, 3.952569e-05, 3.937008e-05, 3.9215687e-05, 3.90625e-05, 3.8910504e-05, 3.875969e-05, 3.861004e-05, 3.8461538e-05, 3.8314174e-05, 3.816794e-05, 3.8022812e-05, 3.7878788e-05, 3.773585e-05, 3.7593985e-05, 3.745318e-05, 3.7313435e-05, 3.717472e-05, 3.703704e-05, 3.690037e-05, 3.6764708e-05, 3.6630034e-05, 3.649635e-05, 3.6363635e-05, 3.6231882e-05, 3.6101083e-05, 3.597122e-05, 3.5842295e-05, 3.5714285e-05, 3.558719e-05, 3.546099e-05, 3.5335688e-05, 3.521127e-05, 3.508772e-05, 3.4965033e-05, 3.4843208e-05, 3.472222e-05, 3.4602075e-05, 3.4482757e-05, 3.436426e-05, 3.4246572e-05, 3.4129695e-05, 3.4013603e-05, 3.3898308e-05, 3.378378e-05, 3.3670036e-05, 3.3557048e-05, 3.3444816e-05, 3.3333334e-05, 3.322259e-05, 3.311258e-05, 3.30033e-05, 3.2894735e-05, 3.2786884e-05, 3.2679738e-05, 3.257329e-05, 3.246753e-05, 3.236246e-05, 3.2258064e-05, 3.215434e-05, 3.205128e-05, 3.1948883e-05, 3.1847136e-05, 3.1746033e-05, 3.164557e-05, 3.1545744e-05, 3.144654e-05, 3.134796e-05, 3.1249998e-05, 3.1152646e-05, 3.10559e-05, 3.0959753e-05, 3.0864197e-05, 3.076923e-05, 3.0674844e-05, 3.058104e-05, 3.0487805e-05, 3.0395136e-05, 3.030303e-05, 3.021148e-05, 3.0120482e-05, 3.003003e-05, 2.994012e-05, 2.9850746e-05, 2.9761904e-05, 2.967359e-05, 2.9585799e-05, 2.9498526e-05, 2.9411765e-05, 2.9325514e-05, 2.9239767e-05, 2.915452e-05, 2.9069766e-05, 2.8985507e-05, 2.8901733e-05, 2.8818442e-05, 2.873563e-05, 2.8653294e-05, 2.8571429e-05, 2.8490027e-05, 2.8409091e-05, 2.8328612e-05, 2.8248587e-05, 2.8169014e-05, 2.8089888e-05, 2.8011204e-05, 2.7932962e-05, 2.7855152e-05, 2.7777778e-05, 2.7700831e-05, 2.762431e-05, 2.7548209e-05, 2.7472528e-05, 2.739726e-05, 2.7322405e-05, 2.7247957e-05, 2.7173914e-05, 2.710027e-05, 2.7027027e-05, 2.6954176e-05, 2.688172e-05, 2.680965e-05, 2.6737967e-05, 2.6666667e-05, 2.6595744e-05, 2.6525198e-05, 2.6455025e-05, 2.6385223e-05, 2.6315789e-05, 2.6246718e-05, 2.617801e-05, 2.6109661e-05, 2.6041667e-05, 2.5974026e-05, 2.5906736e-05, 2.5839794e-05, 2.5773195e-05, 2.570694e-05, 2.5641026e-05, 2.5575448e-05, 2.5510204e-05, 2.5445293e-05, 2.5380712e-05, 2.5316454e-05, 2.5252524e-05, 2.5188916e-05, 2.5125628e-05, 2.5062656e-05, 2.5e-05]
epochs = 1000
lr = 0.001
decay = 1E-4
it_range = np.array(list(range(0,epochs)))
def lr_update(lr,decay,it):
          return lr*(1/(1+decay*it))

def dist_func_best_fit(it_range, decay):
        return lr*(1/(1+decay*it_range))

def lr_predict(epochs,decay,lr):
          for iteration in range(epochs):
                    if iteration == 0:
                              lr_lst = [lr]
                    else:
                              lr_lst.append(lr_update(lr=lr_lst[0],decay=decay,it=iteration))
          return lr_lst

with open("dlr_test.json") as f:
    nadam = json.load(f)
nadam_predict = lr_predict(epochs=len(nadam),decay=decay,lr=lr)
lowest_lr = min(nadam+nadam_predict)
it_test = list(range(len(nadam)))
plt.scatter(it_test,nadam_predict,label="SGD")
plt.scatter(it_test,nadam,label="nadam")
plt.ylim(lowest_lr,lr)
plt.legend()
plt.show()
'''
epoch_legs = [100,100,100,300,3000,3000,3000,3000,3000,8000]
lr_prop_lst = lr_predict(epochs=sum(epoch_legs),decay=decay,lr=lr)

for i in range(0,len(epoch_legs)):
          it_range = list(range(0,epoch_legs[i]))
          if i == 0:
                    lr_broke_lst = lr_predict(epochs=epoch_legs[0],decay=decay,lr=lr)
                    lr_prediction_lst = lr_predict(epochs=epoch_legs[0],decay=decay,lr=lr)
          else:
                    lr_temp_lst = lr_predict(epochs=epoch_legs[i],decay=decay,lr=lr_broke_lst[-1])
                    lr_broke_lst += lr_temp_lst
                    it_range = list(range(sum(epoch_legs[:i]),sum(epoch_legs[:i])+epoch_legs[i]))
                    best_vals, covar = curve_fit(dist_func_best_fit, it_range,lr_prop_lst[sum(epoch_legs[:i])], p0=[1E-4])
                    lr_temp_lst = lr_predict(epochs=epoch_legs[i],decay=best_vals[0],lr=lr_prop_lst[sum(epoch_legs[:i])])
                    lr_prediction_lst += lr_temp_lst
                    print(sum(epoch_legs[:i]))
                    #print(best_vals)
                    
                    



it_range = list(range(0,sum(epoch_legs)))
lowest_lr = min(lr_broke_lst+lr_prop_lst+lr_prediction_lst )


#print(len(it_range))
#print(len(lr_prop_lst))

plt.scatter(it_range,lr_prop_lst,label="correct SGD")
plt.scatter(it_range,lr_broke_lst,label="recompiling using _decayed_lr")
plt.scatter(it_range,lr_prediction_lst,label="prediction")
plt.ylim(lowest_lr,lr)
plt.legend()
plt.show()
'''


'''
lr_vals = np.array(lr_predict(epochs=epochs,decay=decay,lr=lr))

for i in range(1,len(epoch_legs)):
          it_range = np.array(list(range(0,epoch_legs[i])))
          lr_vals = np.array(lr_predict(epochs=epoch_legs[i],decay=decay,lr=lr))
          best_vals, covar = curve_fit(dist_func_best_fit, it_range,lr_vals, p0=[1E-4])
          print(best_vals)
'''

'''
decays = [0.8E-4,0.9E-4,1E-4,1.1E-4,1.2E-4]
lowest_lr = 2
for decay in decays:
          lr_lst = lr_predict(epochs=epochs,decay=decay,lr=lr)
          plt.scatter(it_range,lr_lst, label="decay = {}".format(decay))
          if lr_lst[-1] < lowest_lr:
                    lowest_lr = lr_lst[-1]
plt.ylim(lowest_lr,lr)
plt.xlabel("epochs")
plt.ylabel("learning rate")
plt.title("decays of SGD {} learning rate".format(lr))
plt.legend()
plt.show()
'''
    
